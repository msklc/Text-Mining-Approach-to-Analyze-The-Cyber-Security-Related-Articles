{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Text Mining Approach to Analyze The Cyber Security Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-3: Text Mining\n",
    "\n",
    "__Feature Engineering with NLP techniques__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing of Required Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Data__\n",
    "\n",
    "As mentioned Part-2 that pandas parquet options doesn't support timedelta type. So we need to use __fastparquet__ option, to keep the timedelta type format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum=pd.read_parquet('df_sum_parquet.gzip',engine='fastparquet')\n",
    "df_investigator_cyber=pd.read_parquet('df_investigator_cyber_parque.gzip',engine='fastparquet')\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace contraction words to alternative forms before tokenization\n",
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum['Abstract']=df_sum['Abstract'].replace(replacement_patterns, regex=True)\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merge All Values in Abstract Columns to A Single String__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character number of all Abstract columns is: 13654766\n"
     ]
    }
   ],
   "source": [
    "abstract_list=df_sum['Abstract'].tolist()\n",
    "abstract_sum=' '.join(abstract_list)\n",
    "print('Total character number of all Abstract columns is: {}'.format(len(abstract_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lowercase words: 2136906\n"
     ]
    }
   ],
   "source": [
    "#word tokenization\n",
    "wrd_list = nltk.word_tokenize(abstract_sum)\n",
    "\n",
    "#lowercase\n",
    "wrd_list=[w.lower() for w in wrd_list]\n",
    "print('Total lowercase words: {}'.format(len(wrd_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 1857334\n"
     ]
    }
   ],
   "source": [
    "#remove numbers\n",
    "wrd_list_alpha=[w for w in wrd_list if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Written Form of Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 1852061\n"
     ]
    }
   ],
   "source": [
    "#Create numbers in written form for ignoring\n",
    "num_written= {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', \\\n",
    "             6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten', \\\n",
    "            11: 'eleven', 12: 'twelve', 13: 'thirteen', 14: 'fourteen', \\\n",
    "            15: 'fifteen', 16: 'sixteen', 17: 'seventeen', 18: 'eighteen', \\\n",
    "            19: 'nineteen', 20: 'twenty', 30: 'thirty', 40: 'forty', \\\n",
    "            50: 'fifty', 60: 'sixty', 70: 'seventy', 80: 'eighty', \\\n",
    "            90: 'ninety', 0: 'zero'}\n",
    "\n",
    "num_list=list(np.arange(0,100))\n",
    "\n",
    "num2words_list=[]\n",
    "\n",
    "def num2words(n):\n",
    "    try:\n",
    "        return num_written[n]\n",
    "    except:\n",
    "        try:\n",
    "            return num2words(n-n%10) + num2words(n%10)\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "        \n",
    "for num in num_list:\n",
    "    num2words_list.append(num2words(num))\n",
    "    \n",
    "wrd_list_rm_written_form = [w for w in wrd_list_alpha if w not in num2words_list]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_rm_written_form)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 1132777\n"
     ]
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "wrd_list_rm_stopwords = [w for w in wrd_list_rm_written_form if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(len(wrd_list_rm_stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 1131875\n"
     ]
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "wrd_list_one_len = [w for w in wrd_list_rm_stopwords if len(w)>=2]\n",
    "\n",
    "print('Total words after removing 1-len words: {}'.format(len(wrd_list_one_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Counting The Words Frequency__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words before lemmatization: 29726\n"
     ]
    }
   ],
   "source": [
    "freq_dict_before=nltk.FreqDist(wrd_list_one_len)\n",
    "print('Total unique words before lemmatization: {}'.format(len(freq_dict_before)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 15756), ('project', 13500), ('data', 10357), ('students', 7460), ('systems', 6963), ('new', 6831), ('science', 6174), ('security', 4625), ('development', 4236), ('system', 4159), ('information', 4023), ('support', 3925), ('program', 3870), ('community', 3680), ('education', 3633), ('university', 3622), ('engineering', 3607), ('design', 3590), ('learning', 3518), ('using', 3496), ('network', 3481), ('use', 3479), ('develop', 3395), ('software', 3328), ('provide', 3229), ('tools', 3060), ('cyberinfrastructure', 2987), ('materials', 2930), ('technology', 2855), ('computing', 2791), ('cybersecurity', 2770), ('researchers', 2751), ('scientific', 2646), ('nsf', 2603), ('applications', 2585), ('broader', 2566), ('computer', 2550), ('work', 2543), ('computational', 2532), ('infrastructure', 2492), ('award', 2387), ('analysis', 2384), ('including', 2382), ('control', 2356), ('national', 2351), ('methods', 2351), ('high', 2320), ('used', 2308), ('activities', 2263), ('impact', 2256)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict_before.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words after lemmatization: 26361\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wrd_list_lemmas = [lemmatizer.lemmatize(w) for w in wrd_list_one_len]\n",
    "\n",
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 15763), ('project', 14922), ('system', 11122), ('data', 10357), ('student', 8732), ('science', 7201), ('new', 6831), ('network', 5412), ('program', 5309), ('community', 4828), ('technology', 4686), ('support', 4682), ('security', 4625), ('development', 4450), ('impact', 4424), ('university', 4209), ('information', 4023), ('model', 4019), ('design', 3901), ('application', 3695), ('tool', 3678), ('education', 3636), ('engineering', 3607), ('learning', 3518), ('using', 3496), ('material', 3493), ('use', 3479), ('develop', 3395), ('software', 3330), ('provide', 3229), ('cyberinfrastructure', 2987), ('researcher', 2878), ('computer', 2852), ('resource', 2843), ('infrastructure', 2829), ('process', 2814), ('activity', 2803), ('approach', 2799), ('computing', 2791), ('cybersecurity', 2770), ('study', 2766), ('method', 2750), ('analysis', 2665), ('scientific', 2646), ('work', 2639), ('nsf', 2605), ('broader', 2566), ('computational', 2532), ('workshop', 2523), ('control', 2491)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving The Result__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>research</td>\n",
       "      <td>15763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>14922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system</td>\n",
       "      <td>11122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Count\n",
       "0  research  15763\n",
       "1   project  14922\n",
       "2    system  11122"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FreqDist=pd.DataFrame({'Words':list(freq_dict.keys()),'Count':list(freq_dict.values())})\n",
    "df_FreqDist.sort_values(by=['Count'],ascending=False,inplace=True)\n",
    "df_FreqDist=df_FreqDist.reset_index(drop=True)\n",
    "df_FreqDist.to_csv('FreqDist.csv')\n",
    "df_FreqDist.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract\n",
       "0  0110599  The investigators will conduct a series of exp...\n",
       "1  0112426  This program produces a cadre of computer scie..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new DataFrame\n",
    "df_sum2=df_sum[['AwardID','Abstract']]\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>0646965</td>\n",
       "      <td>This proposal, planning a workshop to examine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AwardID                                           Abstract\n",
       "0    430  0646965  This proposal, planning a workshop to examine ..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum2['Abstract'].replace(replacement_patterns, regex=True, inplace=True)\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Removing Unneccesery Words__\n",
    "\n",
    "We use __NER__ (Named Entity Recognition) function of __spacy__ library to detect named entities (people, places, organizations, dates, times etc.) from the text. After analyzing this words, we understood that they are unnecessary for clustering.\n",
    "\n",
    "An example of visualization of NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This program produces a cadre of computer scientists with strong specializations in information assurance and a commitment to federal service. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cohorts of students complete a \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two-year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " program that integrates intense information assurance studies with research and outreach. Students also spend \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one summer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " as interns in federal agencies. Upon completion of degrees at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the end of two years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " the students then enter the federal cyber service. The program features an emphasis on collaborative research and outreach to the community. The program components train students in information assurance theory and practice while providing an environment that fosters teamwork, strengthens motivation, and builds a sense of professionalism and commitment to service.  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define the nlp object\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc=nlp(str(df_sum2['Abstract'][1]))\n",
    "\n",
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Total NER words: 6\n",
      "Total unique NER words: 6\n",
      "Total words before removing NER: 2448\n",
      "Total words after removing NER: 2419\n"
     ]
    }
   ],
   "source": [
    "#create a list for NER\n",
    "NER_list=[]\n",
    "\n",
    "#Find\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    doc=nlp(str(df_sum2['Abstract'][n]))\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        NER_list.append(ent.text)\n",
    "        \n",
    "NER_list = [' {0} '.format(elem) for elem in NER_list] #Add space to begins and ends of all NERs\n",
    "\n",
    "print('Total NER words: {}'.format(len(NER_list)))\n",
    "NER_list=list(set(NER_list)) #for unique elements in list\n",
    "print('Total unique NER words: {}'.format(len(NER_list)))\n",
    "\n",
    "print('Total words before removing NER: {}'.format(sum(df_sum2['Abstract'].str.len())))\n",
    "\n",
    "for NER in NER_list:\n",
    "    df_sum2['Abstract']=df_sum2['Abstract'].str.replace(NER,' ',regex=False) #Because,some NERs have punctuation\n",
    "print('Total words after removing NER: {}'.format(sum(df_sum2['Abstract'].str.len())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This proposal, planning a workshop to examine questions regarding the security of the cyber infrastructure, aims at gathering the main infrastructure security stakeholders with interdisciplinary expertise on data access, information security, computer network security, data and database security, privacy, and data confidentiality to provide insights and directions toward future strategies for protecting the infrastructure. With the goal of strengthening the security of the infrastructure at all levels, the workshop seeks to determine what questions have to be answered for short and long-term strategies to be successful. Looking at both technical and policy issues and the interaction between the two, the work addresses fundamental questions of infrastructure protection.   Computer security has main thrusts: Confidentiality, Integrity, and (CIA). Security of Infrastructure involves the dynamic interaction of many components and at different levels: Authentication, Authorization, Access control, Auditing, and (AAAAA). Many questions illustrating the need for security in the infrastructure remain open. Hence, highlights include:  *    How security in the infrastructure should be defined and measured  *    How security policies should be defined, whose security policies should apply to various infrastructure components, and how policies should be reconciled when necessary  *    How trust should be assigned to messages that control routing throughout the network, etc.  Additionally, the workshop may also look into:  *    The role that academic infrastructure can play in providing a secure infrastructure,  *    Partnerships between agencies and managers of infrastructure systems that may facilitate the creation of a secure world-wide infrastructure, and  *    Partnerships required ensuring that the technological and computer and information science research challenges can be met.   Broader Impact: Since the infrastructure of the Internet, albeit fragile, underlies the fabric of most people is lives, economy of many organizations, companies, and nations, the workshop expects to present a set of strategies for strengthening security of infrastructure and a set of questions to guide their implementation. The workshop is expected to contribute in attaining sufficient assurance to lead to a desired level of confidence in the infrastructure and the tools and technologies that support it.  '"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2[\"Abstract\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 375\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>0646965</td>\n",
       "      <td>This proposal, planning a workshop to examine ...</td>\n",
       "      <td>[this, proposal, ,, planning, a, workshop, to,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AwardID                                           Abstract  \\\n",
       "0    430  0646965  This proposal, planning a workshop to examine ...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [this, proposal, ,, planning, a, workshop, to,...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization and lowercase\n",
    "df_sum2['Abstract_Tokens'] = df_sum2['Abstract'].str.lower().apply(nltk.word_tokenize)\n",
    "print('Total words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Total words consist of only alphabets: 322\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>0646965</td>\n",
       "      <td>This proposal, planning a workshop to examine ...</td>\n",
       "      <td>[this, proposal, planning, a, workshop, to, ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AwardID                                           Abstract  \\\n",
       "0    430  0646965  This proposal, planning a workshop to examine ...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [this, proposal, planning, a, workshop, to, ex...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    print(n)\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>0646965</td>\n",
       "      <td>This proposal, planning a workshop to examine ...</td>\n",
       "      <td>[proposal, planning, workshop, examine, questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AwardID                                           Abstract  \\\n",
       "0    430  0646965  This proposal, planning a workshop to examine ...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [proposal, planning, workshop, examine, questi...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "#extend the stopwords list with unneccessary words\n",
    "stopwords_list.extend(['abstract','program'])\n",
    "\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proposal',\n",
       " 'planning',\n",
       " 'workshop',\n",
       " 'examine',\n",
       " 'questions',\n",
       " 'regarding',\n",
       " 'security',\n",
       " 'cyber',\n",
       " 'infrastructure',\n",
       " 'aims',\n",
       " 'gathering',\n",
       " 'main',\n",
       " 'infrastructure',\n",
       " 'security',\n",
       " 'stakeholders',\n",
       " 'interdisciplinary',\n",
       " 'expertise',\n",
       " 'data',\n",
       " 'access',\n",
       " 'information',\n",
       " 'security',\n",
       " 'computer',\n",
       " 'nerk',\n",
       " 'security',\n",
       " 'data',\n",
       " 'database',\n",
       " 'security',\n",
       " 'privacy',\n",
       " 'data',\n",
       " 'confidentiality',\n",
       " 'provide',\n",
       " 'insights',\n",
       " 'directions',\n",
       " 'toward',\n",
       " 'future',\n",
       " 'strategies',\n",
       " 'protecting',\n",
       " 'infrastructure',\n",
       " 'goal',\n",
       " 'strengthening',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'levels',\n",
       " 'workshop',\n",
       " 'seeks',\n",
       " 'determine',\n",
       " 'questions',\n",
       " 'answered',\n",
       " 'short',\n",
       " 'strategies',\n",
       " 'successful',\n",
       " 'looking',\n",
       " 'technical',\n",
       " 'policy',\n",
       " 'issues',\n",
       " 'interaction',\n",
       " 'work',\n",
       " 'addresses',\n",
       " 'fundamental',\n",
       " 'questions',\n",
       " 'infrastructure',\n",
       " 'protection',\n",
       " 'computer',\n",
       " 'security',\n",
       " 'main',\n",
       " 'thrusts',\n",
       " 'confidentiality',\n",
       " 'integrity',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'involves',\n",
       " 'dynamic',\n",
       " 'interaction',\n",
       " 'components',\n",
       " 'different',\n",
       " 'levels',\n",
       " 'auditing',\n",
       " 'aaaaa',\n",
       " 'questions',\n",
       " 'illustrating',\n",
       " 'need',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'remain',\n",
       " 'open',\n",
       " 'hence',\n",
       " 'highlights',\n",
       " 'include',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'defined',\n",
       " 'measured',\n",
       " 'security',\n",
       " 'policies',\n",
       " 'defined',\n",
       " 'whose',\n",
       " 'security',\n",
       " 'policies',\n",
       " 'apply',\n",
       " 'various',\n",
       " 'infrastructure',\n",
       " 'components',\n",
       " 'policies',\n",
       " 'reconciled',\n",
       " 'necessary',\n",
       " 'trust',\n",
       " 'assigned',\n",
       " 'messages',\n",
       " 'control',\n",
       " 'routing',\n",
       " 'throughout',\n",
       " 'nerk',\n",
       " 'etc',\n",
       " 'additionally',\n",
       " 'workshop',\n",
       " 'may',\n",
       " 'look',\n",
       " 'role',\n",
       " 'academic',\n",
       " 'infrastructure',\n",
       " 'play',\n",
       " 'providing',\n",
       " 'secure',\n",
       " 'infrastructure',\n",
       " 'partnerships',\n",
       " 'agencies',\n",
       " 'managers',\n",
       " 'infrastructure',\n",
       " 'systems',\n",
       " 'may',\n",
       " 'facilitate',\n",
       " 'creation',\n",
       " 'secure',\n",
       " 'infrastructure',\n",
       " 'partnerships',\n",
       " 'required',\n",
       " 'ensuring',\n",
       " 'technological',\n",
       " 'computer',\n",
       " 'information',\n",
       " 'science',\n",
       " 'research',\n",
       " 'challenges',\n",
       " 'met',\n",
       " 'broader',\n",
       " 'impact',\n",
       " 'since',\n",
       " 'infrastructure',\n",
       " 'internet',\n",
       " 'albeit',\n",
       " 'fragile',\n",
       " 'underlies',\n",
       " 'fabric',\n",
       " 'people',\n",
       " 'lives',\n",
       " 'economy',\n",
       " 'organizations',\n",
       " 'companies',\n",
       " 'nations',\n",
       " 'workshop',\n",
       " 'expects',\n",
       " 'present',\n",
       " 'set',\n",
       " 'strategies',\n",
       " 'strengthening',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'set',\n",
       " 'questions',\n",
       " 'guide',\n",
       " 'implementation',\n",
       " 'workshop',\n",
       " 'expected',\n",
       " 'contribute',\n",
       " 'attaining',\n",
       " 'sufficient',\n",
       " 'assurance',\n",
       " 'lead',\n",
       " 'desired',\n",
       " 'level',\n",
       " 'confidence',\n",
       " 'infrastructure',\n",
       " 'tools',\n",
       " 'technologies',\n",
       " 'support']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2[\"Abstract_Tokens\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after lemmatization: 185\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>0646965</td>\n",
       "      <td>This proposal, planning a workshop to examine ...</td>\n",
       "      <td>[proposal, planning, workshop, examine, questi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  AwardID                                           Abstract  \\\n",
       "0    430  0646965  This proposal, planning a workshop to examine ...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [proposal, planning, workshop, examine, questi...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[lemmatizer.lemmatize(w) for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n])]\n",
    "\n",
    "print('Total words after lemmatization: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['proposal',\n",
       " 'planning',\n",
       " 'workshop',\n",
       " 'examine',\n",
       " 'question',\n",
       " 'regarding',\n",
       " 'security',\n",
       " 'cyber',\n",
       " 'infrastructure',\n",
       " 'aim',\n",
       " 'gathering',\n",
       " 'main',\n",
       " 'infrastructure',\n",
       " 'security',\n",
       " 'stakeholder',\n",
       " 'interdisciplinary',\n",
       " 'expertise',\n",
       " 'data',\n",
       " 'access',\n",
       " 'information',\n",
       " 'security',\n",
       " 'computer',\n",
       " 'nerk',\n",
       " 'security',\n",
       " 'data',\n",
       " 'database',\n",
       " 'security',\n",
       " 'privacy',\n",
       " 'data',\n",
       " 'confidentiality',\n",
       " 'provide',\n",
       " 'insight',\n",
       " 'direction',\n",
       " 'toward',\n",
       " 'future',\n",
       " 'strategy',\n",
       " 'protecting',\n",
       " 'infrastructure',\n",
       " 'goal',\n",
       " 'strengthening',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'level',\n",
       " 'workshop',\n",
       " 'seek',\n",
       " 'determine',\n",
       " 'question',\n",
       " 'answered',\n",
       " 'short',\n",
       " 'strategy',\n",
       " 'successful',\n",
       " 'looking',\n",
       " 'technical',\n",
       " 'policy',\n",
       " 'issue',\n",
       " 'interaction',\n",
       " 'work',\n",
       " 'address',\n",
       " 'fundamental',\n",
       " 'question',\n",
       " 'infrastructure',\n",
       " 'protection',\n",
       " 'computer',\n",
       " 'security',\n",
       " 'main',\n",
       " 'thrust',\n",
       " 'confidentiality',\n",
       " 'integrity',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'involves',\n",
       " 'dynamic',\n",
       " 'interaction',\n",
       " 'component',\n",
       " 'different',\n",
       " 'level',\n",
       " 'auditing',\n",
       " 'aaaaa',\n",
       " 'question',\n",
       " 'illustrating',\n",
       " 'need',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'remain',\n",
       " 'open',\n",
       " 'hence',\n",
       " 'highlight',\n",
       " 'include',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'defined',\n",
       " 'measured',\n",
       " 'security',\n",
       " 'policy',\n",
       " 'defined',\n",
       " 'whose',\n",
       " 'security',\n",
       " 'policy',\n",
       " 'apply',\n",
       " 'various',\n",
       " 'infrastructure',\n",
       " 'component',\n",
       " 'policy',\n",
       " 'reconciled',\n",
       " 'necessary',\n",
       " 'trust',\n",
       " 'assigned',\n",
       " 'message',\n",
       " 'control',\n",
       " 'routing',\n",
       " 'throughout',\n",
       " 'nerk',\n",
       " 'etc',\n",
       " 'additionally',\n",
       " 'workshop',\n",
       " 'may',\n",
       " 'look',\n",
       " 'role',\n",
       " 'academic',\n",
       " 'infrastructure',\n",
       " 'play',\n",
       " 'providing',\n",
       " 'secure',\n",
       " 'infrastructure',\n",
       " 'partnership',\n",
       " 'agency',\n",
       " 'manager',\n",
       " 'infrastructure',\n",
       " 'system',\n",
       " 'may',\n",
       " 'facilitate',\n",
       " 'creation',\n",
       " 'secure',\n",
       " 'infrastructure',\n",
       " 'partnership',\n",
       " 'required',\n",
       " 'ensuring',\n",
       " 'technological',\n",
       " 'computer',\n",
       " 'information',\n",
       " 'science',\n",
       " 'research',\n",
       " 'challenge',\n",
       " 'met',\n",
       " 'broader',\n",
       " 'impact',\n",
       " 'since',\n",
       " 'infrastructure',\n",
       " 'internet',\n",
       " 'albeit',\n",
       " 'fragile',\n",
       " 'underlies',\n",
       " 'fabric',\n",
       " 'people',\n",
       " 'life',\n",
       " 'economy',\n",
       " 'organization',\n",
       " 'company',\n",
       " 'nation',\n",
       " 'workshop',\n",
       " 'expects',\n",
       " 'present',\n",
       " 'set',\n",
       " 'strategy',\n",
       " 'strengthening',\n",
       " 'security',\n",
       " 'infrastructure',\n",
       " 'set',\n",
       " 'question',\n",
       " 'guide',\n",
       " 'implementation',\n",
       " 'workshop',\n",
       " 'expected',\n",
       " 'contribute',\n",
       " 'attaining',\n",
       " 'sufficient',\n",
       " 'assurance',\n",
       " 'lead',\n",
       " 'desired',\n",
       " 'level',\n",
       " 'confidence',\n",
       " 'infrastructure',\n",
       " 'tool',\n",
       " 'technology',\n",
       " 'support']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2[\"Abstract_Tokens\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__\n",
    "\n",
    "Punctuation\n",
    "Punctuation are the unnecessary symbols that are in our corpus documents,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 1030639\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a  of experimen...</td>\n",
       "      <td>[investigator, conduct, experiment, foc, cruci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[produce, cadre, computer, scientist, strong, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a  of experimen...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigator, conduct, experiment, foc, cruci...  \n",
       "1  [produce, cadre, computer, scientist, strong, ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if len(w)>=2]\n",
    "print('Total words after removing 1-len words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tokens_str=df_sum['Abstract_Tokens'].tolist()\n",
    "all_tokens_str=' '.join(tokens_str)\n",
    "print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract2 uniqi!!!\n",
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert Tokens To String Again__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a  of experimen...</td>\n",
       "      <td>[investigator, conduct, experiment, foc, cruci...</td>\n",
       "      <td>investigator conduct experiment foc crucial su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[produce, cadre, computer, scientist, strong, ...</td>\n",
       "      <td>produce cadre computer scientist strong spiali...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a  of experimen...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \\\n",
       "0  [investigator, conduct, experiment, foc, cruci...   \n",
       "1  [produce, cadre, computer, scientist, strong, ...   \n",
       "\n",
       "                                           Abstract2  \n",
       "0  investigator conduct experiment foc crucial su...  \n",
       "1  produce cadre computer scientist strong spiali...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2['Abstract2']=df_sum2['Abstract']\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract2'][n]=' '.join([str(item) for item in df_sum2['Abstract_Tokens'][n]])\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TfidfVectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "X = v.fit_transform(df_sum2['Abstract2'])\n",
    "X.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaaaa',\n",
       " 'aan',\n",
       " 'aand',\n",
       " 'aandm',\n",
       " 'aandp',\n",
       " 'aandt',\n",
       " 'aaron',\n",
       " 'aation',\n",
       " 'aator']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22470"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create New DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaa</th>\n",
       "      <th>aan</th>\n",
       "      <th>aand</th>\n",
       "      <th>aandm</th>\n",
       "      <th>aandp</th>\n",
       "      <th>aandt</th>\n",
       "      <th>aaron</th>\n",
       "      <th>aation</th>\n",
       "      <th>aator</th>\n",
       "      <th>...</th>\n",
       "      <th>zps</th>\n",
       "      <th>zr</th>\n",
       "      <th>zte</th>\n",
       "      <th>ztipanots</th>\n",
       "      <th>zurich</th>\n",
       "      <th>zwitterionic</th>\n",
       "      <th>m</th>\n",
       "      <th>tale</th>\n",
       "      <th>s</th>\n",
       "      <th>ckel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  22470 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaaa  aan  aand  aandm  aandp  aandt  aaron  aation  aator  ...  zps  \\\n",
       "0  0.0    0.0  0.0   0.0    0.0    0.0    0.0    0.0     0.0    0.0  ...  0.0   \n",
       "1  0.0    0.0  0.0   0.0    0.0    0.0    0.0    0.0     0.0    0.0  ...  0.0   \n",
       "\n",
       "    zr  zte  ztipanots  zurich  zwitterionic   m  tale   s  ckel  \n",
       "0  0.0  0.0        0.0     0.0           0.0  0.0    0.0  0.0    0.0  \n",
       "1  0.0  0.0        0.0     0.0           0.0  0.0    0.0  0.0    0.0  \n",
       "\n",
       "[2 rows x 22470 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X.toarray(), columns=v.get_feature_names())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__KMeans Clustering__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 finish...\n",
      "3 finish...\n",
      "4 finish...\n",
      "5 finish...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#for each value of k, we can initialise k_means and use inertia to identify the sum of squared distances of samples to the nearest cluster centre\n",
    "sum_of_squared_distances = []\n",
    "K = range(2,6)\n",
    "for k in K:\n",
    "    k_means = KMeans(n_clusters=k)\n",
    "    model = k_means.fit(df)\n",
    "    sum_of_squared_distances.append(k_means.inertia_)\n",
    "    print(k, 'finish...')\n",
    "    \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('sum_of_squared_distances')\n",
    "plt.title('Elbow method for optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "k_means = KMeans(n_clusters=3)\n",
    "#Run the clustering algorithm\n",
    "model = k_means.fit(df)\n",
    "model\n",
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = k_means.predict(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a  of experimen...</td>\n",
       "      <td>[investigator, conduct, experiment, foc, cruci...</td>\n",
       "      <td>investigator conduct experiment foc crucial su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[produce, cadre, computer, scientist, strong, ...</td>\n",
       "      <td>produce cadre computer scientist strong spiali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a  of experimen...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \\\n",
       "0  [investigator, conduct, experiment, foc, cruci...   \n",
       "1  [produce, cadre, computer, scientist, strong, ...   \n",
       "\n",
       "                                           Abstract2  Label  \n",
       "0  investigator conduct experiment foc crucial su...      1  \n",
       "1  produce cadre computer scientist strong spiali...      0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=list(y_hat)\n",
    "df_sum2['Label']=labels\n",
    "df_sum2.to_csv('df_sum_clustering.csv',sep=';')\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[produce, cadre, computer, scientist, strong, ...</td>\n",
       "      <td>produce cadre computer scientist strong spiali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0114016</td>\n",
       "      <td>This projt relieves the shortage of qualified ...</td>\n",
       "      <td>[projt, relief, shortage, qualified, informati...</td>\n",
       "      <td>projt relief shortage qualified information as...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0201873</td>\n",
       "      <td>In response to the national need for informati...</td>\n",
       "      <td>[response, national, need, information, thnolo...</td>\n",
       "      <td>response national need information thnology wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0210334</td>\n",
       "      <td>Utica ollege (U), yrace  (U), and the tate  of...</td>\n",
       "      <td>[utica, ollege, yrace, tate, ew, thnology, erk...</td>\n",
       "      <td>utica ollege yrace tate ew thnology erkimer ot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0221722</td>\n",
       "      <td>This projt will ex the framework for supportin...</td>\n",
       "      <td>[projt, ex, framework, supporting, surity, res...</td>\n",
       "      <td>projt ex framework supporting surity reseh con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5181</th>\n",
       "      <td>1441724</td>\n",
       "      <td>Operating systems (O) form the core of the trt...</td>\n",
       "      <td>[operating, system, form, core, trted, computi...</td>\n",
       "      <td>operating system form core trted computing bas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5235</th>\n",
       "      <td>1534602</td>\n",
       "      <td>The broader impact/commercial potial of this m...</td>\n",
       "      <td>[broader, potial, mall, bine, eseh, projt, dra...</td>\n",
       "      <td>broader potial mall bine eseh projt dramatic i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>1642134</td>\n",
       "      <td>erk infrastructure at  campes is complex and s...</td>\n",
       "      <td>[erk, infrastructure, campes, complex, sophist...</td>\n",
       "      <td>erk infrastructure campes complex sophisticate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5275</th>\n",
       "      <td>1642158</td>\n",
       "      <td>erk infrastructure at  campes is complex and s...</td>\n",
       "      <td>[erk, infrastructure, campes, complex, sophist...</td>\n",
       "      <td>erk infrastructure campes complex sophisticate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>1936040</td>\n",
       "      <td>ystem-on-hip (o) is the dring force behind com...</td>\n",
       "      <td>[dring, force, behind, computing, commcation, ...</td>\n",
       "      <td>dring force behind computing commcation wide v...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>695 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AwardID                                           Abstract  \\\n",
       "1     0112426  This program produces a cadre of computer scie...   \n",
       "2     0114016  This projt relieves the shortage of qualified ...   \n",
       "6     0201873  In response to the national need for informati...   \n",
       "15    0210334  Utica ollege (U), yrace  (U), and the tate  of...   \n",
       "18    0221722  This projt will ex the framework for supportin...   \n",
       "...       ...                                                ...   \n",
       "5181  1441724  Operating systems (O) form the core of the trt...   \n",
       "5235  1534602  The broader impact/commercial potial of this m...   \n",
       "5274  1642134  erk infrastructure at  campes is complex and s...   \n",
       "5275  1642158  erk infrastructure at  campes is complex and s...   \n",
       "5411  1936040  ystem-on-hip (o) is the dring force behind com...   \n",
       "\n",
       "                                        Abstract_Tokens  \\\n",
       "1     [produce, cadre, computer, scientist, strong, ...   \n",
       "2     [projt, relief, shortage, qualified, informati...   \n",
       "6     [response, national, need, information, thnolo...   \n",
       "15    [utica, ollege, yrace, tate, ew, thnology, erk...   \n",
       "18    [projt, ex, framework, supporting, surity, res...   \n",
       "...                                                 ...   \n",
       "5181  [operating, system, form, core, trted, computi...   \n",
       "5235  [broader, potial, mall, bine, eseh, projt, dra...   \n",
       "5274  [erk, infrastructure, campes, complex, sophist...   \n",
       "5275  [erk, infrastructure, campes, complex, sophist...   \n",
       "5411  [dring, force, behind, computing, commcation, ...   \n",
       "\n",
       "                                              Abstract2  Label  \n",
       "1     produce cadre computer scientist strong spiali...      0  \n",
       "2     projt relief shortage qualified information as...      0  \n",
       "6     response national need information thnology wo...      0  \n",
       "15    utica ollege yrace tate ew thnology erkimer ot...      0  \n",
       "18    projt ex framework supporting surity reseh con...      0  \n",
       "...                                                 ...    ...  \n",
       "5181  operating system form core trted computing bas...      0  \n",
       "5235  broader potial mall bine eseh projt dramatic i...      0  \n",
       "5274  erk infrastructure campes complex sophisticate...      0  \n",
       "5275  erk infrastructure campes complex sophisticate...      0  \n",
       "5411  dring force behind computing commcation wide v...      0  \n",
       "\n",
       "[695 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2[df_sum2['Label']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum2.head(30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
