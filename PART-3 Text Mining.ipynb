{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Text Mining Approach to Analyze The Cyber Security Related Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART-3: Text Mining\n",
    "\n",
    "__Feature Engineering with NLP techniques__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Importing of Required Libraries__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from autocorrect import Speller\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Data__\n",
    "\n",
    "As mentioned Part-2 that pandas parquet options doesn't support timedelta type. So we need to use __fastparquet__ option, to keep the timedelta type format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum=pd.read_parquet('df_sum_parquet.gzip',engine='fastparquet')\n",
    "df_investigator_cyber=pd.read_parquet('df_investigator_cyber_parque.gzip',engine='fastparquet')\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-) Word Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>AwardTitle</th>\n",
       "      <th>AwardEffectiveDate</th>\n",
       "      <th>AwardExpirationDate</th>\n",
       "      <th>AwardAmount</th>\n",
       "      <th>ProgramOfficer</th>\n",
       "      <th>Institution_Name</th>\n",
       "      <th>Institution_StateName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Year</th>\n",
       "      <th>Award_Duration</th>\n",
       "      <th>AwardAmount_Million</th>\n",
       "      <th>Abstract_Lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>Collaborative Research Testing Affect Control ...</td>\n",
       "      <td>2001-08-15</td>\n",
       "      <td>2004-07-31</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>Patricia White</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>2001</td>\n",
       "      <td>1081 days</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>Federal Cyber Service Initiative</td>\n",
       "      <td>2001-06-01</td>\n",
       "      <td>2007-06-30</td>\n",
       "      <td>149995.0</td>\n",
       "      <td>Timothy V. Fossum</td>\n",
       "      <td>University of Tulsa</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>2001</td>\n",
       "      <td>2220 days</td>\n",
       "      <td>0.15</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                         AwardTitle  \\\n",
       "0  0110599  Collaborative Research Testing Affect Control ...   \n",
       "1  0112426                   Federal Cyber Service Initiative   \n",
       "\n",
       "  AwardEffectiveDate AwardExpirationDate  AwardAmount     ProgramOfficer  \\\n",
       "0         2001-08-15          2004-07-31     300000.0     Patricia White   \n",
       "1         2001-06-01          2007-06-30     149995.0  Timothy V. Fossum   \n",
       "\n",
       "        Institution_Name Institution_StateName  \\\n",
       "0  University of Arizona               Arizona   \n",
       "1    University of Tulsa              Oklahoma   \n",
       "\n",
       "                                            Abstract  Year Award_Duration  \\\n",
       "0  The investigators will conduct a series of exp...  2001      1081 days   \n",
       "1  This program produces a cadre of computer scie...  2001      2220 days   \n",
       "\n",
       "   AwardAmount_Million  Abstract_Lenght  \n",
       "0                 0.30             2194  \n",
       "1                 0.15              765  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace contraction words to alternative forms before tokenization\n",
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum['Abstract']=df_sum['Abstract'].replace(replacement_patterns, regex=True)\n",
    "df_sum.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Merge All Values in Abstract Columns to A Single String__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total character number of all Abstract columns is: 17247941\n"
     ]
    }
   ],
   "source": [
    "abstract_list=df_sum['Abstract'].tolist()\n",
    "abstract_sum=' '.join(abstract_list)\n",
    "print('Total character number of all Abstract columns is: {}'.format(len(abstract_sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lowercase words: 2699956\n"
     ]
    }
   ],
   "source": [
    "#word tokenization\n",
    "wrd_list = nltk.word_tokenize(abstract_sum)\n",
    "\n",
    "#lowercase\n",
    "wrd_list=[w.lower() for w in wrd_list]\n",
    "print('Total lowercase words: {}'.format(len(wrd_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 2345704\n"
     ]
    }
   ],
   "source": [
    "#remove numbers\n",
    "wrd_list_alpha=[w for w in wrd_list if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_alpha)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Written Form of Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 2339123\n"
     ]
    }
   ],
   "source": [
    "#Create numbers in written form for ignoring\n",
    "num_written= {1: 'one', 2: 'two', 3: 'three', 4: 'four', 5: 'five', \\\n",
    "             6: 'six', 7: 'seven', 8: 'eight', 9: 'nine', 10: 'ten', \\\n",
    "            11: 'eleven', 12: 'twelve', 13: 'thirteen', 14: 'fourteen', \\\n",
    "            15: 'fifteen', 16: 'sixteen', 17: 'seventeen', 18: 'eighteen', \\\n",
    "            19: 'nineteen', 20: 'twenty', 30: 'thirty', 40: 'forty', \\\n",
    "            50: 'fifty', 60: 'sixty', 70: 'seventy', 80: 'eighty', \\\n",
    "            90: 'ninety', 0: 'zero'}\n",
    "\n",
    "num_list=list(np.arange(0,100))\n",
    "\n",
    "num2words_list=[]\n",
    "\n",
    "def num2words(n):\n",
    "    try:\n",
    "        return num_written[n]\n",
    "    except:\n",
    "        try:\n",
    "            return num2words(n-n%10) + num2words(n%10)\n",
    "        except:\n",
    "            return 'None'\n",
    "\n",
    "        \n",
    "for num in num_list:\n",
    "    num2words_list.append(num2words(num))\n",
    "    \n",
    "wrd_list_rm_written_form = [w for w in wrd_list_alpha if w not in num2words_list]\n",
    "print('Total words consist of only alphabets: {}'.format(len(wrd_list_rm_written_form)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 1430837\n"
     ]
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "wrd_list_rm_stopwords = [w for w in wrd_list_rm_written_form if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(len(wrd_list_rm_stopwords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 1429707\n"
     ]
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "wrd_list_one_len = [w for w in wrd_list_rm_stopwords if len(w)>=2]\n",
    "\n",
    "print('Total words after removing 1-len words: {}'.format(len(wrd_list_one_len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Counting The Words Frequency__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words before lemmatization: 32869\n"
     ]
    }
   ],
   "source": [
    "freq_dict_before=nltk.FreqDist(wrd_list_one_len)\n",
    "print('Total unique words before lemmatization: {}'.format(len(freq_dict_before)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 19775), ('project', 16842), ('data', 12652), ('systems', 9240), ('students', 9053), ('new', 8683), ('science', 7465), ('security', 5938), ('system', 5444), ('development', 5256), ('information', 5057), ('support', 4805), ('program', 4688), ('design', 4687), ('engineering', 4513), ('university', 4483), ('using', 4420), ('network', 4417), ('education', 4416), ('community', 4376), ('develop', 4324), ('use', 4251), ('learning', 4248), ('software', 4207), ('provide', 4036), ('materials', 3872), ('tools', 3748), ('cyberinfrastructure', 3592), ('technology', 3590), ('computing', 3432), ('researchers', 3413), ('applications', 3397), ('broader', 3298), ('work', 3224), ('nsf', 3182), ('cybersecurity', 3170), ('scientific', 3157), ('infrastructure', 3137), ('control', 3135), ('computer', 3132), ('computational', 3108), ('methods', 3043), ('analysis', 3024), ('high', 3000), ('award', 2992), ('including', 2975), ('used', 2974), ('models', 2857), ('national', 2846), ('impact', 2846)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict_before.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words after lemmatization: 29227\n"
     ]
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wrd_list_lemmas = [lemmatizer.lemmatize(w) for w in wrd_list_one_len]\n",
    "\n",
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 frequency words:\n",
      "[('research', 19785), ('project', 18508), ('system', 14684), ('data', 12652), ('student', 10589), ('science', 8697), ('new', 8683), ('network', 7002), ('program', 6420), ('security', 5938), ('technology', 5916), ('community', 5824), ('support', 5752), ('impact', 5602), ('development', 5515), ('university', 5237), ('design', 5101), ('model', 5099), ('information', 5057), ('application', 4856), ('material', 4616), ('engineering', 4513), ('tool', 4501), ('using', 4420), ('education', 4419), ('develop', 4324), ('use', 4251), ('learning', 4248), ('software', 4209), ('provide', 4036), ('process', 3613), ('approach', 3592), ('cyberinfrastructure', 3592), ('researcher', 3572), ('infrastructure', 3570), ('method', 3544), ('computer', 3513), ('resource', 3513), ('computing', 3432), ('study', 3393), ('activity', 3387), ('analysis', 3360), ('work', 3344), ('control', 3312), ('broader', 3298), ('nsf', 3184), ('cybersecurity', 3170), ('scientific', 3157), ('computational', 3108), ('award', 3095)]\n"
     ]
    }
   ],
   "source": [
    "print('First 50 frequency words:\\n{}'.format(freq_dict.most_common(50)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Saving The Result__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>research</td>\n",
       "      <td>19785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project</td>\n",
       "      <td>18508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system</td>\n",
       "      <td>14684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Words  Count\n",
       "0  research  19785\n",
       "1   project  18508\n",
       "2    system  14684"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FreqDist=pd.DataFrame({'Words':list(freq_dict.keys()),'Count':list(freq_dict.values())})\n",
    "df_FreqDist.sort_values(by=['Count'],ascending=False,inplace=True)\n",
    "df_FreqDist=df_FreqDist.reset_index(drop=True)\n",
    "df_FreqDist.to_csv('FreqDist.csv')\n",
    "df_FreqDist.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B-) Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract\n",
       "0  0110599  The investigators will conduct a series of exp...\n",
       "1  0112426  This program produces a cadre of computer scie..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new DataFrame\n",
    "df_sum2=df_sum[['AwardID','Abstract']][:30]\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Replacing Of Contraction Words__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract\n",
       "0  0110599  The investigators will conduct a series of exp...\n",
       "1  0112426  This program produces a cadre of computer scie..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_patterns = {\n",
    "    r\"won\\'t\": \"will not\",\n",
    "    r\"can\\'t\": \"cannot\",\n",
    "    r\"i\\'m\": \"i am\",\n",
    "    r\"ain\\'t\": \"is not\",\n",
    "    r\"(\\w+)\\'ll\": \"\\g<1> will\",\n",
    "    r\"(\\w+)n\\'t\": \"\\g<1> not\",\n",
    "    r\"(\\w+)\\'ve\": \"\\g<1> have\",\n",
    "    r\"(\\w+)\\'s\": \"\\g<1> is\",\n",
    "    r\"(\\w+)\\'re\": \"\\g<1> are\",\n",
    "    r\"(\\w+)\\'d\": \"\\g<1> would\",\n",
    "    r\"&\": \"and\",\n",
    "    r\"<br/>\":\" \"}\n",
    "\n",
    "df_sum2['Abstract'].replace(replacement_patterns, regex=True, inplace=True)\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Removing Unneccesery Words__\n",
    "\n",
    "We use __NER__ (Named Entity Recognition) function of __spacy__ library to detect named entities (people, places, organizations, dates, times etc.) from the text. After analyzing this words, we understood that they are unnecessary for clustering.\n",
    "\n",
    "An example of visualization of NER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This program produces a cadre of computer scientists with strong specializations in information assurance and a commitment to federal service. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " cohorts of students complete a \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two-year\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " program that integrates intense information assurance studies with research and outreach. Students also spend \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    one summer\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " as interns in federal agencies. Upon completion of degrees at \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the end of two years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " the students then enter the federal cyber service. The program features an emphasis on collaborative research and outreach to the community. The program components train students in information assurance theory and practice while providing an environment that fosters teamwork, strengthens motivation, and builds a sense of professionalism and commitment to service.  </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#define the nlp object\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "doc=nlp(str(df_sum2['Abstract'][1]))\n",
    "\n",
    "displacy.render(doc, style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique NER words: 16\n",
      "Total words after removing NER: 52927\n",
      "Total words after removing NER: 52402\n"
     ]
    }
   ],
   "source": [
    "#create a list for NER\n",
    "NER_list=[]\n",
    "\n",
    "#Find\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    doc=nlp(str(df_sum2['Abstract'][n]))\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        NER_list.append(ent.text)\n",
    "\n",
    "NER_list=list(set(NER_list)) #for unique elements in list\n",
    "print('Total unique NER words: {}'.format(len(NER_list)))\n",
    "\n",
    "print('Total words before removing NER: {}'.format(sum(df_sum2['Abstract'].str.len())))\n",
    "\n",
    "for NER in NER_list:\n",
    "    df_sum2['Abstract']=df_sum2['Abstract'].str.replace(NER,'')\n",
    "print('Total words after removing NER: {}'.format(sum(df_sum2['Abstract'].str.len())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tokenization and LowerCase__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 8516\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[the, investigators, will, conduct, a, series,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[this, program, produces, a, cadre, of, comput...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [the, investigators, will, conduct, a, series,...  \n",
       "1  [this, program, produces, a, cadre, of, comput...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization and lowercase\n",
    "df_sum2['Abstract_Tokens'] = df_sum2['Abstract'].str.lower().apply(nltk.word_tokenize)\n",
    "print('Total words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Numbers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words consist of only alphabets: 7335\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[the, investigators, will, conduct, a, series,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[this, program, produces, a, cadre, of, comput...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [the, investigators, will, conduct, a, series,...  \n",
       "1  [this, program, produces, a, cadre, of, comput...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove numbers\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w.isalpha()]\n",
    "print('Total words consist of only alphabets: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove Stopwords__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing stopwords: 4217\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigators, conduct, series, experiments, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produces, cadre, computer, scientist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigators, conduct, series, experiments, ...  \n",
       "1  [program, produces, cadre, computer, scientist...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define stopwords list\n",
    "stopwords_list=nltk.corpus.stopwords.words('english')\n",
    "\n",
    "#extend the stopwords list\n",
    "stopwords_list.extend(['cannot','many','much','also','well','better','via'])\n",
    "\n",
    "#extend the stopwords list with unneccessary words\n",
    "stopwords_list.extend(['abstract'])\n",
    "\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if w not in stopwords_list]\n",
    "print('Total words after removing stopwords: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Lemmatization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after lemmatization: 4217\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigator, conduct, series, experiment, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produce, cadre, computer, scientist,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigator, conduct, series, experiment, fo...  \n",
       "1  [program, produce, cadre, computer, scientist,...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[lemmatizer.lemmatize(w) for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n])]\n",
    "\n",
    "print('Total words after lemmatization: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Remove 1-Length Words__\n",
    "\n",
    "Punctuation\n",
    "Punctuation are the unnecessary symbols that are in our corpus documents,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after removing 1-len words: 4203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigator, conduct, series, experiment, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produce, cadre, computer, scientist,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \n",
       "0  [investigator, conduct, series, experiment, fo...  \n",
       "1  [program, produce, cadre, computer, scientist,...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 1-len words\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract_Tokens'][n]=[w for w in (abstract for abstract in df_sum2['Abstract_Tokens'][n]) if len(w)>=2]\n",
    "print('Total words after removing 1-len words: {}'.format(sum(df_sum2['Abstract_Tokens'].str.len())))\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstract2 uniqi!!!\n",
    "#Recounting the Words Frequency\n",
    "freq_dict=nltk.FreqDist(wrd_list_lemmas)\n",
    "\n",
    "print('Total unique words after lemmatization: {}'.format(len(freq_dict)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert Tokens To String Again__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigator, conduct, series, experiment, fo...</td>\n",
       "      <td>investigator conduct series experiment focus c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produce, cadre, computer, scientist,...</td>\n",
       "      <td>program produce cadre computer scientist stron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \\\n",
       "0  [investigator, conduct, series, experiment, fo...   \n",
       "1  [program, produce, cadre, computer, scientist,...   \n",
       "\n",
       "                                           Abstract2  \n",
       "0  investigator conduct series experiment focus c...  \n",
       "1  program produce cadre computer scientist stron...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2['Abstract2']=df_sum2['Abstract']\n",
    "for n in range(df_sum2.shape[0]):\n",
    "    df_sum2['Abstract2'][n]=' '.join([str(item) for item in df_sum2['Abstract_Tokens'][n]])\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TfidfVectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "v = TfidfVectorizer()\n",
    "X = v.fit_transform(df_sum2['Abstract2'])\n",
    "X.toarray()[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ability',\n",
       " 'able',\n",
       " 'academic',\n",
       " 'accelerate',\n",
       " 'acceptable',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accompanying',\n",
       " 'accountability',\n",
       " 'accuracy']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1427"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create New DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>accelerate</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>access</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accompanying</th>\n",
       "      <th>accountability</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>workforce</th>\n",
       "      <th>working</th>\n",
       "      <th>workplace</th>\n",
       "      <th>workshop</th>\n",
       "      <th>world</th>\n",
       "      <th>worldwide</th>\n",
       "      <th>would</th>\n",
       "      <th>yamacrew</th>\n",
       "      <th>yet</th>\n",
       "      <th>youth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  1427 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability  able  academic  accelerate  acceptable  access  accessible  \\\n",
       "0      0.0   0.0       0.0         0.0         0.0     0.0         0.0   \n",
       "1      0.0   0.0       0.0         0.0         0.0     0.0         0.0   \n",
       "\n",
       "   accompanying  accountability  accuracy  ...  workforce  working  workplace  \\\n",
       "0           0.0             0.0       0.0  ...        0.0      0.0        0.0   \n",
       "1           0.0             0.0       0.0  ...        0.0      0.0        0.0   \n",
       "\n",
       "   workshop  world  worldwide  would  yamacrew  yet  youth  \n",
       "0       0.0    0.0        0.0    0.0       0.0  0.0    0.0  \n",
       "1       0.0    0.0        0.0    0.0       0.0  0.0    0.0  \n",
       "\n",
       "[2 rows x 1427 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=X.toarray(), columns=v.get_feature_names())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  5,  5,  9,  7, 10, 11,  1,  2, 10,  1,  6,  0,  3,  2,  2,  5,\n",
       "        7,  0,  7,  5,  8,  0,  8,  8,  8,  3,  3,  3,  3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means = KMeans(n_clusters=12)\n",
    "#Run the clustering algorithm\n",
    "model = k_means.fit(df)\n",
    "model\n",
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = k_means.predict(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#for each value of k, we can initialise k_means and use inertia to identify the sum of squared distances of samples to the nearest cluster centre\n",
    "sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    k_means = KMeans(n_clusters=k)\n",
    "    model = k_means.fit(df)\n",
    "    sum_of_squared_distances.append(k_means.inertia_)\n",
    "    \n",
    "    \n",
    "plt.plot(K, sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('sum_of_squared_distances')\n",
    "plt.title('Elbow method for optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 1, 0, 2, 2, 1, 0, 2, 1, 0, 1, 2, 1, 2, 1, 0, 1, 2, 2,\n",
       "       0, 2, 2, 2, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means = KMeans(n_clusters=3)\n",
    "#Run the clustering algorithm\n",
    "model = k_means.fit(df)\n",
    "model\n",
    "#Generate cluster predictions and store in y_hat\n",
    "y_hat = k_means.predict(X)\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0110599</td>\n",
       "      <td>The investigators will conduct a series of exp...</td>\n",
       "      <td>[investigator, conduct, series, experiment, fo...</td>\n",
       "      <td>investigator conduct series experiment focus c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produce, cadre, computer, scientist,...</td>\n",
       "      <td>program produce cadre computer scientist stron...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AwardID                                           Abstract  \\\n",
       "0  0110599  The investigators will conduct a series of exp...   \n",
       "1  0112426  This program produces a cadre of computer scie...   \n",
       "\n",
       "                                     Abstract_Tokens  \\\n",
       "0  [investigator, conduct, series, experiment, fo...   \n",
       "1  [program, produce, cadre, computer, scientist,...   \n",
       "\n",
       "                                           Abstract2  Label  \n",
       "0  investigator conduct series experiment focus c...      1  \n",
       "1  program produce cadre computer scientist stron...      2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=list(y_hat)\n",
    "df_sum2['Label']=labels\n",
    "df_sum2.to_csv('df_sum_clustering.csv')\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AwardID</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Abstract_Tokens</th>\n",
       "      <th>Abstract2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0112426</td>\n",
       "      <td>This program produces a cadre of computer scie...</td>\n",
       "      <td>[program, produce, cadre, computer, scientist,...</td>\n",
       "      <td>program produce cadre computer scientist stron...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0114016</td>\n",
       "      <td>This project relieves the shortage of qualifie...</td>\n",
       "      <td>[project, relief, shortage, qualified, informa...</td>\n",
       "      <td>project relief shortage qualified information ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0201303</td>\n",
       "      <td>MS-  and   This award provides partial support...</td>\n",
       "      <td>[award, provides, partial, support, active, re...</td>\n",
       "      <td>award provides partial support active research...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0201873</td>\n",
       "      <td>In response to the national need for informati...</td>\n",
       "      <td>[response, national, need, information, techno...</td>\n",
       "      <td>response national need information technology ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0204267</td>\n",
       "      <td>- Good, , ,  ,   :   The Research Compnt of a ...</td>\n",
       "      <td>[good, research, compnt, model, college, itwf,...</td>\n",
       "      <td>good research compnt model college itwf award ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0208848</td>\n",
       "      <td>The objective of the proposed research is to i...</td>\n",
       "      <td>[objective, proposed, research, improve, nerk,...</td>\n",
       "      <td>objective proposed research improve nerk secur...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0210334</td>\n",
       "      <td>(UC),  (), and  Technology at  (),  () and  (...</td>\n",
       "      <td>[uc, technology, improving, institutional, reg...</td>\n",
       "      <td>uc technology improving institutional regional...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0220785</td>\n",
       "      <td>This scholarship project provides funds for  c...</td>\n",
       "      <td>[scholarship, project, provides, fund, compute...</td>\n",
       "      <td>scholarship project provides fund computer sci...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0221722</td>\n",
       "      <td>This project will examine the framework for su...</td>\n",
       "      <td>[project, examine, framework, supporting, secu...</td>\n",
       "      <td>project examine framework supporting security ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0224889</td>\n",
       "      <td>Information security has become a critical con...</td>\n",
       "      <td>[information, security, become, critical, conc...</td>\n",
       "      <td>information security become critical concern g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0225191</td>\n",
       "      <td>Information security has become a critical con...</td>\n",
       "      <td>[information, security, become, critical, conc...</td>\n",
       "      <td>information security become critical concern g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0225235</td>\n",
       "      <td>Information security has become a critical con...</td>\n",
       "      <td>[information, security, become, critical, conc...</td>\n",
       "      <td>information security become critical concern g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AwardID                                           Abstract  \\\n",
       "1   0112426  This program produces a cadre of computer scie...   \n",
       "2   0114016  This project relieves the shortage of qualifie...   \n",
       "6   0201303  MS-  and   This award provides partial support...   \n",
       "7   0201873  In response to the national need for informati...   \n",
       "10  0204267  - Good, , ,  ,   :   The Research Compnt of a ...   \n",
       "14  0208848  The objective of the proposed research is to i...   \n",
       "16  0210334   (UC),  (), and  Technology at  (),  () and  (...   \n",
       "20  0220785  This scholarship project provides funds for  c...   \n",
       "21  0221722  This project will examine the framework for su...   \n",
       "23  0224889  Information security has become a critical con...   \n",
       "24  0225191  Information security has become a critical con...   \n",
       "25  0225235  Information security has become a critical con...   \n",
       "\n",
       "                                      Abstract_Tokens  \\\n",
       "1   [program, produce, cadre, computer, scientist,...   \n",
       "2   [project, relief, shortage, qualified, informa...   \n",
       "6   [award, provides, partial, support, active, re...   \n",
       "7   [response, national, need, information, techno...   \n",
       "10  [good, research, compnt, model, college, itwf,...   \n",
       "14  [objective, proposed, research, improve, nerk,...   \n",
       "16  [uc, technology, improving, institutional, reg...   \n",
       "20  [scholarship, project, provides, fund, compute...   \n",
       "21  [project, examine, framework, supporting, secu...   \n",
       "23  [information, security, become, critical, conc...   \n",
       "24  [information, security, become, critical, conc...   \n",
       "25  [information, security, become, critical, conc...   \n",
       "\n",
       "                                            Abstract2  Label  \n",
       "1   program produce cadre computer scientist stron...      2  \n",
       "2   project relief shortage qualified information ...      2  \n",
       "6   award provides partial support active research...      2  \n",
       "7   response national need information technology ...      2  \n",
       "10  good research compnt model college itwf award ...      2  \n",
       "14  objective proposed research improve nerk secur...      2  \n",
       "16  uc technology improving institutional regional...      2  \n",
       "20  scholarship project provides fund computer sci...      2  \n",
       "21  project examine framework supporting security ...      2  \n",
       "23  information security become critical concern g...      2  \n",
       "24  information security become critical concern g...      2  \n",
       "25  information security become critical concern g...      2  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sum2[df_sum2['Label']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array from number of occurrences\n",
    "occ = np.asarray(X.sum(axis=0)).ravel().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowListFrame = pd.DataFrame({'term': v.get_feature_names(), 'occurrences': occ})\n",
    "bowListFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import texthero as hero\n",
    "df_sum2['tfidf'] = hero.tfidf(df_sum2['Abstract2'])\n",
    "df_sum2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__TEST__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfs = tfidf.fit_transform(df_sum2['Abstract'].values)\n",
    "tfs.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_tf_idf = NearestNeighbors(metric='cosine', algorithm='brute')\n",
    "model_tf_idf.fit(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf_idf.transforms(tfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
